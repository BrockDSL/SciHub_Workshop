{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![dsl_logo](dsl_logo.png)\n",
    "\n",
    "\n",
    "# Sci Hub Usage in Niagara\n",
    "## A Data Science case study\n",
    "\n",
    "This tutorial is meant to give you an introduction to the main ideas behind data science by analyzing usage logs of the Sci-Hub website in the Niagara region using the Python programming language. This tutorial is presented in a Jupyter notebook that blends code into web pages. Please feel free to run through this on your own.\n",
    "\n",
    "Jupyter Notebooks are pretty easy to use. They have code 'cells' that allow you to enter and run code. Let's demonstrate. Click in the box below and hit the _Run_ button in the menu above, or the play button on the left side of the cell (if you're using Google Colab, it looks like a circle with a triangle in it) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's just print a basic message\n",
    "print(\"Welcome to our Data Science Tutorial\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background info\n",
    "\n",
    "\n",
    "![scihub_log](https://upload.wikimedia.org/wikipedia/fr/c/c4/Sci-Hub_logo.png)\n",
    "\n",
    "SciHub is a resource that a person can use to download Academic PDFs. There is some controversy with it however. Periodically the owner of the site releases usage logs that curious people like us can review. The most recent [log file](https://zenodo.org/record/1158301) is from 2017. We are going to explore this data to see if we can spot anything interesting. At the same time we're going to learn some [Python](https://www.python.org/), in particular the [Panadas](https://pandas.pydata.org/) library and a visualization library called [Matplotlib](https://matplotlib.org/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Libraries and the data\n",
    "\n",
    "Our first step is to get Python ready and to load the datafile. The next cell will take care of that. We'll also look at the first 10 lines of our data file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Our Libraries\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Loading our Data\n",
    "data = pd.read_csv(\"https://raw.githubusercontent.com/BrockDSL/SciHub_Workshop/master/niagara_scihub_2017_use.tab\",sep=\"\\t\")\n",
    "\n",
    "#Tell pandas what is in the data\n",
    "data.columns = [\"date\",\"doi\",\"pub_code\",\"user_code\",\"country\",\"city\",\"lat\",\"long\"]\n",
    "data = data.sort_values(by = \"date\", ascending = False)\n",
    "\n",
    "#Let's look at the first ten lines of the data\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looking at the data\n",
    "\n",
    "Let's look  at what different columns are in our data.\n",
    "\n",
    "\n",
    "- _date_ - The date the article was downloaded\n",
    "- _doi_ - Is something like the serial number of the article [more info](https://apastyle.apa.org/learn/faqs/what-is-doi)\n",
    "- _pub_code_ - a randomized serial number that represents the publisher behind the article\n",
    "- _user_code_ - a randomized serial number that represents the user who downloaed the article\n",
    "- _county_ - The country the usage is from. (The original datafile is global)\n",
    "- _city_ - Which city in Niagara the user lives in\n",
    "- _lat_ - the latitude of the center of the city found in _city_\n",
    "- _long_ - the longtitude of the center of the city found in _city_\n",
    "\n",
    "\n",
    "Don't work the data is totally randomized!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some general questions about averages\n",
    "\n",
    "Let's ask some basic questions about what is in our data.\n",
    "\n",
    "### How many entries are in our datafile?\n",
    "\n",
    "We just apply the `len` function to our dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_papers = len(data)\n",
    "print(total_papers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How many unique users are in the data?\n",
    "\n",
    "We'll select the _user_code_ column and see how many unique values there are with `nunique()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_users = data[\"user_code\"].nunique()\n",
    "print(unique_users)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How many unique paper are in the data?\n",
    "\n",
    "We'll select the _doi_ column and see how many unique values there are with `nunique()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_papers = data[\"doi\"].nunique()\n",
    "print(unique_papers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How many unique publishers are in the data?\n",
    "\n",
    "Same as before but witht the _pub_code_ column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_publishers = data[\"pub_code\"].nunique()\n",
    "print(unique_publishers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Now run the next cell to figure our some averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Average papers downloaded per user: \", total_papers / unique_users)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "Can you come up with other interesting averages?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "##  Lost Revenue?\n",
    "\n",
    "If each paper on average cost *30* how much revenue was 'lost'. * is the multiplication operator. What if each paper was on average *50*?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cost_per_article = 30\n",
    "lost_revenue = cost_per_article * total_papers\n",
    "\n",
    "print(\"Approximately\",lost_revenue,\"dollars would be lost.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Most popular \n",
    "\n",
    "\n",
    "### Which paper has been downloaded the most\n",
    "\n",
    "This is a bit more complex. We first need to `groupby()` then `count()` and finally sort our result to go from most to least. Our result may look a bit odd but it is applying the `count()` function against all of the columns and showing us the result. In our case that won't make a difference and we can use any value in columns 2 on as the answer to our question.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_article = data.groupby(\"doi\").count().sort_values(by = \"date\", ascending = False)\n",
    "top_article"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Holy cats! One article was downloaded *a lot*. Have a look at the [article](https://dx.doi.org/10.1071/CH06322) Take a look at what the stated price is to access tha article."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Which user has downloaded the most papers\n",
    "\n",
    "Let's use the same rationale and figure out who our busiest users were. Notice the same behaviour with `count()` shows up there too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_users = data.groupby(\"user_code\").count().sort_values(by = \"date\", ascending = False)\n",
    "top_users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow, there has been some busy users in the data!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Location questions\n",
    "\n",
    "Which cities in Niagara used SciHub the most?\n",
    "\n",
    "We'll apply `groupby()` to the _city_ column and get a `count()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data.groupby(\"city\").count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that St. Catharines did the most downloading by a good margin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize some results\n",
    "\n",
    "Let's draw some charts with our data to see if we can spot any other interesting details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How many papers do users download?\n",
    "\n",
    "Well plot out a [histogram](https://en.wikipedia.org/wiki/Histogram) of user downloads amounts. Explore different values for `bins` to see if you can get a better graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Let's get the data we need in a new `dataframe`\n",
    "user_downloads = data.groupby(\"user_code\").count().sort_values( by = \"doi\",ascending = False).doi\n",
    "\n",
    "#how many different values on the x-axis we'll use for the data.\n",
    "bins = 200\n",
    "\n",
    "#Now we plot it all out\n",
    "plt.hist(user_downloads, bins)\n",
    "plt.ylabel(\"Users\")\n",
    "plt.xlabel(\"Downloads\")\n",
    "plt.title(\"Downloads per user\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we saw above the average papers per user is at 16 and change. We can see with this graph however that the data does not follow a [standard distribution](https://www.bmj.com/about-bmj/resources-readers/publications/statistics-square-one/2-mean-and-standard-deviation)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What's popular in Thorold\n",
    "\n",
    "Let's graph out how many papers per user but just in Thorold. For fun we'll make it look like an [XKCD](https://xkcd.com/) cartoon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's get the data we need in a new `dataframe`\n",
    "thorold_downloads = data[data[\"city\"] == \"Thorold\"]\n",
    "thorold_downloads = thorold_downloads.groupby(\"user_code\").count().sort_values( by = \"doi\",ascending = False).doi\n",
    "\n",
    "#how many different values on the x-axis we'll use for the data.\n",
    "bins = 50\n",
    "\n",
    "with plt.xkcd():\n",
    "    #Now we plot it all out\n",
    "    plt.hist(thorold_downloads[0:100], bins)\n",
    "    plt.ylabel(\"Users\")\n",
    "    plt.xlabel(\"Downloads\")\n",
    "    plt.title(\"Thorold Downloads per user\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Everyone likes pie\n",
    "\n",
    "In our last example we'll draw a pie-graph of the top 5 cities in the data. 'Cause everybody loves pie. We'll use a `value_counts()` to count how many times each city shows up in the data. and we'll grab the `unique()` values in the _city_ column to be our labels. We apply the slice operator `[0:5]` which grabs only the first five values. Let's also make it like XKCD, 'cause why not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities = data[\"city\"].value_counts()[0:5]\n",
    "city_labels = data[\"city\"].unique()[0:5]\n",
    "\n",
    "with plt.xkcd():\n",
    "    plt.pie(cities,labels=city_labels)\n",
    "    plt.title(\"Top 5 Cities that 'download'\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The End\n",
    "\n",
    "Thanks for taking a look at our tutorial. Now you have the basics all taken care of. Here are some links you might find useful:\n",
    "\n",
    "- [Introduction to Python](https://brockdsl.github.io/Intro_to_Python_Workshop/) - Just like the name says, it's our first intro to Python workshop\n",
    "- [Pyhon Part 2: Introducion to Data Science](https://brockdsl.github.io/Python_2.0_Workshop/) - Dig into a bit more Python and find out how to use it to do some data science stuff\n",
    "- [Machine Learning with Python](https://brockdsl.github.io/Machine_Learning_with_Python/) - Once you get the basics this workshop will run through how to make predictions with your data.\n",
    "- [Workshop listings](https://experiencebu.brocku.ca/organization/dsl) - All of the workshops we host can be found on ExperienceBU or if you're not a student at Brock, we list everything on [Eventbrite](https://brockdsl.eventbrite.com) too\n",
    "- [Python the Hard Way](https://learntocodetogether.com/learn-python-the-hard-way-free-ebook-download/) - Don't let the name fool you. This great resource will teach you all of the basic of Python.\n",
    "\n",
    "Check out the [DSL website](https://brocku.ca/library/dsl) too. We're also on [Twitter](https://twitter.com/brock_dsl) and [Insta](https://www.instagram.com/brock_dsl)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
